import re
import uuid
import os.path
import chromadb
import requests
import tempfile
import threading
import pandas as pd
import gradio as gr
from re import Pattern
from __init__ import *
from llama_cpp import Llama
from gradio_modal import Modal
from template import create_doc
from tinydb import TinyDB, where
from logging_custom import FileLogger
from typing import List, Optional, Tuple
from datetime import datetime, timedelta, date
from langchain.docstore.document import Document
from huggingface_hub.file_download import http_get
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter


logger = get_logger(os.path.basename(__file__).replace(".py", "_") + str(datetime.now().date()))
f_logger = FileLogger(__name__, f"{LOGGING_DIR}/answers_bot.log", mode='a', level=logging.INFO)
os.environ["TOKENIZERS_PARALLELISM"] = "false"


class LocalChatGPT:

    def __init__(self):
        self.llama_model: Optional[Llama] = self.initialize_app()
        self.embeddings = HuggingFaceEmbeddings(model_name=EMBEDDER_NAME, cache_folder=MODELS_DIR)
        self.db: Optional[Chroma] = None
        self.collection: str = "all-documents"
        self.load_db()
        self.mode: str = MODES[0]
        self.system_prompt = self._get_default_system_prompt(self.mode)
        self.semaphore = threading.Semaphore()
        self._queue = 0
        self.tiny_db = TinyDB(f'{DATA_QUESTIONS}/tiny_db.json', indent=4, ensure_ascii=False)

    @staticmethod
    def initialize_app() -> Llama:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞.
        :return:
        """
        os.makedirs(MODELS_DIR, exist_ok=True)
        final_model_path = os.path.join(MODELS_DIR, MODEL_NAME)
        os.makedirs(os.path.dirname(final_model_path), exist_ok=True)

        if not os.path.exists(final_model_path):
            with open(final_model_path, "wb") as f:
                http_get(REPO, f)

        return Llama(
            n_gpu_layers=43,
            model_path=final_model_path,
            n_ctx=CONTEXT_SIZE,
            n_parts=1,
        )

    @staticmethod
    def load_single_document(file_path: str) -> Document:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç.
        :param file_path:
        :return:
        """
        ext: str = "." + file_path.rsplit(".", 1)[-1]
        assert ext in LOADER_MAPPING
        loader_class, loader_args = LOADER_MAPPING[ext]
        loader = loader_class(file_path, **loader_args)
        return loader.load()[0]

    @staticmethod
    def upload_files(files: List[tempfile.TemporaryFile]) -> List[str]:
        """

        :param files:
        :return:
        """
        return [f.name for f in files]

    @staticmethod
    def process_text(text: str) -> Optional[str]:
        """

        :param text:
        :return:
        """
        lines: list = text.split("\n")
        lines = [line for line in lines if len(line.strip()) > 2]
        text = "\n".join(lines).strip()
        return "" if len(text) < 10 else text

    def update_text_db(
        self,
        fixed_documents: List[Document],
        ids: List[str]
    ) -> tuple[bool, str]:
        """

        :param fixed_documents:
        :param ids:
        :return:
        """
        data: dict = self.db.get()
        files_db = {os.path.basename(dict_data['source']) for dict_data in data["metadatas"]}
        files_load = {os.path.basename(dict_data.metadata["source"]) for dict_data in fixed_documents}
        if same_files := files_load & files_db:
            gr.Warning("–§–∞–π–ª—ã " + ", ".join(same_files) + " –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è, –ø–æ—ç—Ç–æ–º—É –æ–Ω–∏ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            for file in same_files:
                pattern: Pattern[str] = re.compile(fr'{file.replace(".txt", "")}\d*$')
                self.db.delete([x for x in data['ids'] if pattern.match(x)])
            self.db = self.db.from_documents(
                documents=fixed_documents,
                embedding=self.embeddings,
                ids=ids,
                persist_directory=DB_DIR,
                collection_name=self.collection,
            )
            file_warning = f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(fixed_documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤! –ú–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã."
            return True, file_warning
        return False, "–§—Ä–∞–≥–º–µ–Ω—Ç—ã –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!"

    def build_index(
        self,
        file_paths: List[str],
        chunk_size: int,
        chunk_overlap: int
    ):
        """

        :param file_paths:
        :param chunk_size:
        :param chunk_overlap:
        :return:
        """
        load_documents: List[Document] = [self.load_single_document(path) for path in file_paths]
        text_splitter: RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap
        )
        documents = text_splitter.split_documents(load_documents)
        fixed_documents: List[Document] = []
        for doc in documents:
            doc.page_content = self.process_text(doc.page_content)
            if not doc.page_content:
                continue
            fixed_documents.append(doc)

        ids: List[str] = [
            f"{os.path.basename(doc.metadata['source']).replace('.txt', '')}{i}"
            for i, doc in enumerate(fixed_documents)
        ]
        is_updated, file_warning = self.update_text_db(fixed_documents, ids)
        if is_updated:
            return file_warning
        self.db = self.db.from_documents(
            documents=fixed_documents,
            embedding=self.embeddings,
            ids=ids,
            persist_directory=DB_DIR,
            collection_name=self.collection,
        )
        file_warning = f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(fixed_documents)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤! –ú–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã."
        os.chmod(FILES_DIR, 0o0777)
        return file_warning

    @staticmethod
    def _get_default_system_prompt(mode: str) -> str:
        return QUERY_SYSTEM_PROMPT if mode == "DB" else LLM_SYSTEM_PROMPT

    def _set_system_prompt(self, system_prompt_input: str) -> None:
        self.system_prompt = system_prompt_input

    def _set_current_mode(self, mode: str):
        self.mode = mode
        self._set_system_prompt(self._get_default_system_prompt(mode))
        # Update placeholder and allow interaction if default system prompt is set
        if self.system_prompt:
            return gr.update(placeholder=self.system_prompt, interactive=True)
        # Update placeholder and disable interaction if no default system prompt is set
        else:
            return gr.update(placeholder=self.system_prompt, interactive=False)

    @staticmethod
    def calculate_end_date(history):
        long_days = re.findall(r"\d{1,4} –¥", history[-1][0])
        list_dates = []
        for day in long_days:
            day = int(day.replace(" –¥", ""))
            start_dates = re.findall(r"\d{1,2}[.]\d{1,2}[.]\d{2,4}", history[-1][1])
            for date_ in start_dates:
                list_dates.append(date_)
                end_date = datetime.strptime(date_, '%d.%m.%Y') + timedelta(days=day)
                end_date = end_date.strftime('%d.%m.%Y')
                list_dates.append(end_date)
                return [[f"–ù–∞—á–∞–ª–æ –æ—Ç–ø—É—Å–∫–∞ - {list_dates[0]}. –ö–æ–Ω–µ—Ü –æ—Ç–ø—É—Å–∫–∞ - {list_dates[1]}", None]]

    def get_dates_in_question(self, history, generator, mode):
        if mode == MODES[2]:
            partial_text = ""
            for token in generator:
                for data in token["choices"]:
                    letters = data["delta"].get("content", "")
                    partial_text += letters
                    f_logger.finfo(letters)
                    history[-1][1] = partial_text
            return self.calculate_end_date(history)

    def get_message_generator(self, history, retrieved_docs, mode, top_k, top_p, temp, uid):
        model = self.llama_model
        last_user_message = history[-1][0]
        pattern = r'<a\s+[^>]*>(.*?)</a>'
        files = re.findall(pattern, retrieved_docs)
        for file in files:
            retrieved_docs = re.sub(fr'<a\s+[^>]*>{file}</a>', file, retrieved_docs)
        if retrieved_docs and mode == MODES[1]:
            last_user_message = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {retrieved_docs}\n\n–ò—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: " \
                                f"{last_user_message}"
        elif mode == MODES[2]:
            last_user_message = f"{last_user_message}\n\n" \
                                f"–°–µ–≥–æ–¥–Ω—è {datetime.now().strftime('%d.%m.%Y')} —á–∏—Å–ª–æ. " \
                                f"–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ —É–∫–∞–∑–∞–Ω –≥–æ–¥, —Ç–æ –ø–∏—à–∏ {date.today().year}. " \
                                f"–ù–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–∞–∫, –±–µ–∑ –∫–∞–∫–∏—Ö –ª–∏–±–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π: " \
                                f"–ü—Ä–æ—à—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –µ–∂–µ–≥–æ–¥–Ω—ã–π –æ–ø–ª–∞—á–∏–≤–∞–µ–º—ã–π –æ—Ç–ø—É—Å–∫ —Å " \
                                f"(–¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –æ—Ç–ø—É—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY) –ø–æ " \
                                f"(–¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ—Ç–ø—É—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY)."
        logger.info(f"–í–æ–ø—Ä–æ—Å –±—ã–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω [uid - {uid}]")
        f_logger.finfo(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] - –í–æ–ø—Ä–æ—Å: {history[-1][0]} - "
                       f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\n")
        history_user = [
            {"role": "user", "content": user_message}
            for user_message, _ in history[-4:-1]
        ]
        generator = model.create_chat_completion(
            messages=[
                {
                    "role": "system", "content": self.system_prompt
                },
                *history_user,
                {
                    "role": "user", "content": last_user_message
                },

            ],
            stream=True,
            temperature=temp,
            top_k=top_k,
            top_p=top_p
        )
        return model, generator, files

    @staticmethod
    def get_list_files(history, mode, scores, files, partial_text):
        if files:
            partial_text += SOURCES_SEPARATOR
            sources_text = [
                f"{index}. {source}"
                for index, source in enumerate(files, start=1)
            ]
            threshold = 0.44
            if scores and scores[0] < threshold:
                partial_text += "\n\n\n".join(sources_text)
            elif scores:
                partial_text += sources_text[0]
            history[-1][1] = partial_text
        elif mode == MODES[2]:
            file = create_doc(partial_text, "–¢–∏—Ç–æ–≤–∞", "–°–µ—Ä–≥–µ—è –°–µ—Ä–≥–µ–µ–≤–∏—á–∞", "–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞",
                              "–û—Ç–¥–µ–ª –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è")
            partial_text += f'\n\n\n–§–∞–π–ª: {file}'
            history[-1][1] = partial_text
        return history

    def bot(self, history, mode, retrieved_docs, top_p, top_k, temp, scores, uid):
        """

        :param history:
        :param mode:
        :param retrieved_docs:
        :param top_p:
        :param top_k:
        :param temp:
        :param scores:
        :param uid:
        :return:
        """
        logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏ "
                    f"[uid - {uid}]")
        self.semaphore.acquire()
        if not history or not history[-1][0]:
            yield history[:-1]
            self.semaphore.release()
            return
        model, generator, files = self.get_message_generator(history, retrieved_docs, mode, top_k, top_p, temp, uid)
        partial_text = ""
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ [uid - {uid}]")
        f_logger.finfo(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] - –û—Ç–≤–µ—Ç: ")
        if message := self.get_dates_in_question(history, generator, mode):
            model, generator, files = self.get_message_generator(message, retrieved_docs, mode, top_k, top_p, temp, uid)
        elif mode == MODES[2]:
            model, generator, files = self.get_message_generator(history, retrieved_docs, mode, top_k, top_p, temp, uid)
        try:
            token: dict
            for token in generator:
                for data in token["choices"]:
                    letters = data["delta"].get("content", "")
                    partial_text += letters
                    f_logger.finfo(letters)
                    history[-1][1] = partial_text
                    yield history
        except Exception as ex:
            logger.error(f"Error - {ex}")
            partial_text += "\n–°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. " \
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –µ–≥–æ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–¥–∞–≤–∞–µ–º–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö"
            history[-1][1] = partial_text
            yield history
        f_logger.finfo(f" - [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\n\n")
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –∑–∞–∫–æ–Ω—á–µ–Ω–∞ [uid - {uid}]")
        yield self.get_list_files(history, mode, scores, files, partial_text)
        self._queue -= 1
        self.semaphore.release()

    def user(self, message, history):
        uid = uuid.uuid4()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞. –û—á–µ—Ä–µ–¥—å - {self._queue}. UID - [{uid}]")
        self.semaphore.acquire()
        if history is None:
            history = []
        new_history = history + [[message, None]]
        self._queue += 1
        self.semaphore.release()
        logger.info(f"–ó–∞–∫–æ–Ω—á–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞. UID - [{uid}]")
        return "", new_history, uid

    def retrieve(self, history, collection_radio, k_documents: int, uid: str) -> Tuple[str, list]:
        """

        :param history:
        :param collection_radio:
        :param k_documents:
        :param uid:
        :return:
        """
        if not self.db or collection_radio != MODES[0] or not history or not history[-1][0]:
            return "–ü–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–¥–∞–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤", []
        last_user_message = history[-1][0]
        docs = self.db.similarity_search_with_score(last_user_message, k_documents)
        scores: list = []
        data: dict = {}
        for doc in docs:
            url = f"""<a href="file/{doc[0].metadata["source"]}" target="_blank" 
                rel="noopener noreferrer">{os.path.basename(doc[0].metadata["source"])}</a>"""
            document: str = f'–î–æ–∫—É–º–µ–Ω—Ç - {url} ‚Üì'
            score: float = round(doc[1], 2)
            scores.append(score)
            if document in data:
                data[document] += "\n\n" + f"Score: {score}, Text: {doc[0].page_content}"
            else:
                data[document] = f"Score: {score}, Text: {doc[0].page_content}"
        list_data: list = [f"{doc}\n\n{text}" for doc, text in data.items()]
        logger.info(f"–ü–æ–ª—É—á–∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã [uid - {uid}]")
        if not list_data:
            return "–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ –Ω–µ—Ç—É", scores
        return "\n\n\n".join(list_data), scores

    def ingest_files(self):
        self.load_db()
        files = {
            os.path.basename(ingested_document["source"])
            for ingested_document in self.db.get()["metadatas"]
        }
        return list(files)

    def delete_doc(self, documents: str):
        self.load_db()
        all_documents: dict = self.db.get()
        for_delete_ids: list = []
        list_documents: List[str] = documents.strip().split("\n")
        for ingested_document, doc_id in zip(all_documents["metadatas"], all_documents["ids"]):
            print(ingested_document)
            if os.path.basename(ingested_document["source"]) in list_documents:
                for_delete_ids.append(doc_id)
        if for_delete_ids:
            self.db.delete(for_delete_ids)
        return gr.update(choices=self.ingest_files())

    def get_analytics(self) -> pd.DataFrame:
        try:
            return pd.DataFrame(self.tiny_db.all()).sort_values('–°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞', ascending=False)
        except KeyError:
            return pd.DataFrame(self.tiny_db.all())

    def calculate_analytics(self, messages, analyse=None):
        message = messages[-1][0] if messages else None
        answer = messages[-1][1] if message else None
        filter_query = where('–°–æ–æ–±—â–µ–Ω–∏—è') == message
        if result := self.tiny_db.search(filter_query):
            if analyse is None:
                self.tiny_db.update(
                    {
                        '–û—Ç–≤–µ—Ç—ã': answer,
                        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π': result[0]['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π'] + 1,
                        '–°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞': str(datetime.now())
                    },
                    cond=filter_query
                )
            else:
                self.tiny_db.update({'–û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞': analyse}, cond=filter_query)
                gr.Info("–û—Ç–∑—ã–≤ –æ—Ç–≤–µ—Ç—É –ø–æ—Å—Ç–∞–≤–ª–µ–Ω")
        elif message is not None:
            self.tiny_db.insert(
                {'–°–æ–æ–±—â–µ–Ω–∏—è': message, '–û—Ç–≤–µ—Ç—ã': answer, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π': 1, '–û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞': None,
                 '–°—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞': str(datetime.now())}
            )
        return self.get_analytics()

    @staticmethod
    def login(username, password):
        """

        :param username:
        :param password:
        :return:
        """
        response = requests.post(
            "http://0.0.0.0:8001/token",
            data={"username": username, "password": password},
            headers={"Content-Type": "application/x-www-form-urlencoded"},
        )
        if response.status_code == 200:
            return {"access_token": response.json()["access_token"], "is_success": True}
        logger.error(response.json()["detail"])
        return {"access_token": None, "is_success": False, "message": response.json()["detail"]}

    @staticmethod
    def get_current_user_info(local_data):
        """

        :param local_data:
        :return:
        """
        if isinstance(local_data, dict) and local_data.get("is_success", False):
            response = requests.get(
                "http://0.0.0.0:8001/users/me",
                headers={"Authorization": f"Bearer {local_data['access_token']}"}
            )
            logger.info(f"User is {response.json().get('username')}")
            is_logged_in = response.status_code == 200
        else:
            is_logged_in = False

        obj_tabs = [local_data] + [gr.update(visible=is_logged_in) for _ in range(3)]
        if is_logged_in:
            obj_tabs.append(gr.update(value="–í—ã–π—Ç–∏", icon=str(LOGOUT_ICON)))
        else:
            obj_tabs.append(gr.update(value="–í–æ–π—Ç–∏", icon=str(LOGIN_ICON)))
        obj_tabs.append(gr.update(visible=not is_logged_in))
        if isinstance(local_data, dict):
            obj_tabs.append(local_data.get("message", MESSAGE_LOGIN))

        return obj_tabs

    def login_or_logout(self, local_data, login_btn):
        """

        :param local_data:
        :param login_btn:
        :return:
        """
        data = self.get_current_user_info(local_data)
        if isinstance(data[0], dict) and data[0].get("access_token"):
            obj_tabs = [gr.update(visible=False)] + [gr.update(visible=False) for _ in range(3)]
            obj_tabs.append(gr.update(value="–í–æ–π—Ç–∏", icon=str(LOGIN_ICON)))
            return obj_tabs
        obj_tabs = [gr.update(visible=True)] + [gr.update(visible=False) for _ in range(3)]
        obj_tabs.append(login_btn)
        return obj_tabs

    def load_db(self):
        """

        :return:
        """
        client = chromadb.PersistentClient(path=DB_DIR)
        self.db = Chroma(
            client=client,
            collection_name=self.collection,
            embedding_function=self.embeddings,
        )

    def run(self):
        """

        :return:
        """
        with gr.Blocks(
                title="MakarGPT",
                theme=gr.themes.Soft().set(
                    body_background_fill="white",
                    block_background_fill="#e1e5e8",
                    block_label_background_fill="#2042b9",
                    block_label_background_fill_dark="#2042b9",
                    block_label_text_color="white",
                    checkbox_label_background_fill_selected="#1f419b",
                    checkbox_label_background_fill_selected_dark="#1f419b",
                    checkbox_background_color_selected="#111d3d",
                    checkbox_background_color_selected_dark="#111d3d",
                    input_background_fill="#e1e5e8",
                    button_primary_background_fill="#1f419b",
                    button_primary_background_fill_dark="#1f419b",
                    shadow_drop_lg="5px 5px 5px 5px rgb(0 0 0 / 0.1)"
                ),
                css=BLOCK_CSS
        ) as demo:
            # –í–∞—à –ª–æ–≥–æ—Ç–∏–ø –∏ —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
            logo_svg = f'<img src="{FAVICON_PATH}" width="48px" style="display: inline">'
            header_html = f"""<h1><center>{logo_svg} –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –†—É—Å–∫–æ–Ω (–±–µ—Ç–∞-–≤–µ—Ä—Å–∏—è)</center></h1>"""

            with gr.Row():
                gr.HTML(header_html)
                login_btn = gr.DuplicateButton("–í–æ–π—Ç–∏", variant="primary", size="lg", elem_id="login_btn",
                                               icon=str(LOGIN_ICON))

            uid = gr.State(None)
            scores = gr.State(None)
            local_data = gr.JSON({}, visible=False)
            file_paths = gr.State(None)

            with gr.Tab("–ß–∞—Ç"):
                with gr.Row():
                    collection_radio = gr.Radio(
                        choices=MODES,
                        value=self.mode,
                        show_label=False
                    )

                with gr.Row():
                    with gr.Column(scale=10):
                        chatbot = gr.Chatbot(
                            label="–î–∏–∞–ª–æ–≥",
                            height=500,
                            show_copy_button=True,
                            show_share_button=True,
                            avatar_images=(
                                AVATAR_USER,
                                AVATAR_BOT
                            )
                        )

                with gr.Row():
                    with gr.Column(scale=20):
                        msg = gr.Textbox(
                            label="–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ",
                            show_label=False,
                            placeholder="üëâ –ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å",
                            container=False
                        )
                    with gr.Column(scale=3, min_width=100):
                        submit = gr.Button("üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å", variant="primary")

                with gr.Row(elem_id="buttons"):
                    like = gr.Button(value="üëç –ü–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å")
                    dislike = gr.Button(value="üëé –ù–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å")
                    clear = gr.Button(value="üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å")

                with gr.Row():
                    gr.Markdown(
                        "<center>–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –º–æ–∂–µ—Ç –¥–æ–ø—É—Å–∫–∞—Ç—å –æ—à–∏–±–∫–∏, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. "
                        "–û—Ç–≤–µ—Ç—ã —Ç–∞–∫–∂–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø—Ä–∏–∑—ã–≤–æ–º –∫ –¥–µ–π—Å—Ç–≤–∏—é</center>"
                    )

            with gr.Tab("–î–æ–∫—É–º–µ–Ω—Ç—ã", visible=False) as documents_tab:
                with gr.Row():
                    with gr.Column(scale=3):
                        upload_button = gr.Files(
                            label="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                            file_count="multiple"
                        )
                        file_warning = gr.Markdown("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

                    with gr.Column(scale=7):
                        list_files = self.ingest_files()
                        files_selected = gr.Dropdown(
                            choices=list_files,
                            label="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è",
                            value=None,
                            multiselect=True
                        )
                        delete = gr.Button("üßπ –£–¥–∞–ª–∏—Ç—å", variant="primary")

            with gr.Tab("–ù–∞—Å—Ç—Ä–æ–π–∫–∏", visible=False) as settings_tab:
                with gr.Row(elem_id="model_selector_row"):
                    models = [MODEL_NAME]
                    gr.Dropdown(
                        choices=models,
                        value=models[0],
                        interactive=True,
                        show_label=False,
                        container=False,
                    )
                with gr.Accordion("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã", open=False):
                    with gr.Tab(label="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"):
                        k_documents = gr.Slider(
                            minimum=1,
                            maximum=12,
                            value=6,
                            step=1,
                            interactive=True,
                            label="–ö–æ–ª-–≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"
                        )
                    with gr.Tab(label="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ä–µ–∑–∫–∏"):
                        chunk_size = gr.Slider(
                            minimum=128,
                            maximum=1792,
                            value=1408,
                            step=128,
                            interactive=True,
                            label="–†–∞–∑–º–µ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤",
                        )
                        chunk_overlap = gr.Slider(
                            minimum=0,
                            maximum=400,
                            value=400,
                            step=10,
                            interactive=True,
                            label="–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ"
                        )
                    with gr.Tab(label="–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"):
                        top_p = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.9,
                            step=0.05,
                            interactive=True,
                            label="Top-p",
                        )
                        top_k = gr.Slider(
                            minimum=10,
                            maximum=100,
                            value=80,
                            step=5,
                            interactive=True,
                            label="Top-k",
                        )
                        temp = gr.Slider(
                            minimum=0.0,
                            maximum=2.0,
                            value=0.1,
                            step=0.1,
                            interactive=True,
                            label="Temp"
                        )

                with gr.Accordion("–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç", open=False):
                    system_prompt = gr.Textbox(
                        placeholder=QUERY_SYSTEM_PROMPT,
                        lines=5,
                        show_label=False
                    )
                    # On blur, set system prompt to use in queries
                    system_prompt.blur(
                        self._set_system_prompt,
                        inputs=system_prompt,
                    )

                with gr.Accordion("–ö–æ–Ω—Ç–µ–∫—Å—Ç", open=True):
                    with gr.Column(variant="compact"):
                        retrieved_docs = gr.Markdown(
                            value="–ü–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–¥–∞–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤",
                            label="–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã",
                            show_label=True
                        )

            with gr.Tab("–õ–æ–≥–∏ –¥–∏–∞–ª–æ–≥–æ–≤", visible=False) as logging_tab:
                with gr.Row():
                    with gr.Column():
                        analytics = gr.DataFrame(
                            value=self.get_analytics,
                            interactive=False,
                            wrap=True
                        )

            with Modal(visible=False) as modal:
                with gr.Column(variant="panel"):
                    gr.HTML("<h1><center>–í—Ö–æ–¥</center></h1>")
                    message_login = gr.HTML(MESSAGE_LOGIN)
                    login = gr.Textbox(
                        label="–õ–æ–≥–∏–Ω",
                        placeholder="–í–≤–µ–¥–∏—Ç–µ –ª–æ–≥–∏–Ω",
                        show_label=True,
                        max_lines=1
                    )
                    password = gr.Textbox(
                        label="–ü–∞—Ä–æ–ª—å",
                        placeholder="–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å",
                        show_label=True,
                        type="password"
                    )
                    submit_login = gr.Button("üë§ –í–æ–π—Ç–∏", variant="primary")
                    cancel_login = gr.Button("‚õî –û—Ç–º–µ–Ω–∞", variant="secondary")

            submit_login.click(
                fn=self.login,
                inputs=[login, password],
                outputs=[local_data]
            ).success(
                fn=self.get_current_user_info,
                inputs=[local_data],
                outputs=[local_data, documents_tab, settings_tab, logging_tab, login_btn, modal, message_login]
            ).success(
                fn=None,
                inputs=[local_data],
                outputs=None,
                js="(v) => {setStorage('access_token', v)}"
            )

            login_btn.click(
                fn=self.login_or_logout,
                inputs=[local_data, login_btn],
                outputs=[modal, documents_tab, settings_tab, logging_tab, login_btn]
            ).success(
                fn=None,
                inputs=None,
                outputs=[local_data],
                js="() => {removeStorage('access_token')}"
            )
            cancel_login.click(
                fn=lambda: Modal(visible=False),
                inputs=None,
                outputs=modal
            )

            collection_radio.change(
                fn=self._set_current_mode, inputs=collection_radio, outputs=system_prompt
            )

            # Upload files
            upload_button.upload(
                fn=self.upload_files,
                inputs=[upload_button],
                outputs=[file_paths],
                queue=True,
            ).success(
                fn=self.build_index,
                inputs=[file_paths, chunk_size, chunk_overlap],
                outputs=[file_warning],
                queue=True
            ).success(
                self.ingest_files,
                outputs=files_selected
            )

            # Delete documents from db
            delete.click(
                fn=self.delete_doc,
                inputs=files_selected,
                outputs=[files_selected]
            )

            # Pressing Enter
            msg.submit(
                fn=self.user,
                inputs=[msg, chatbot],
                outputs=[msg, chatbot, uid],
                queue=False,
            ).success(
                fn=self.retrieve,
                inputs=[chatbot, collection_radio, k_documents, uid],
                outputs=[retrieved_docs, scores],
                queue=True,
            ).success(
                fn=self.bot,
                inputs=[chatbot, collection_radio, retrieved_docs, top_p, top_k, temp, scores, uid],
                outputs=chatbot,
                queue=True
            ).success(
                fn=self.calculate_analytics,
                inputs=chatbot,
                outputs=analytics,
                queue=True,
            )

            # Pressing the button
            submit.click(
                fn=self.user,
                inputs=[msg, chatbot],
                outputs=[msg, chatbot, uid],
                queue=False,
            ).success(
                fn=self.retrieve,
                inputs=[chatbot, collection_radio, k_documents, uid],
                outputs=[retrieved_docs, scores],
                queue=True,
            ).success(
                fn=self.bot,
                inputs=[chatbot, collection_radio, retrieved_docs, top_p, top_k, temp, scores, uid],
                outputs=chatbot,
                queue=True
            ).success(
                fn=self.calculate_analytics,
                inputs=chatbot,
                outputs=analytics,
                queue=True,
            )

            # Like
            like.click(
                fn=self.calculate_analytics,
                inputs=[chatbot, like],
                outputs=[analytics],
                queue=True,
            )

            # Dislike
            dislike.click(
                fn=self.calculate_analytics,
                inputs=[chatbot, dislike],
                outputs=[analytics],
                queue=True,
            )

            # Clear history
            clear.click(lambda: None, None, chatbot, queue=False, js=JS)

            demo.load(
                fn=self.get_current_user_info,
                inputs=[local_data],
                outputs=[local_data, documents_tab, settings_tab, logging_tab, login_btn],
                js=LOCAL_STORAGE
            )

        demo.queue(max_size=128, api_open=False)
        return demo
